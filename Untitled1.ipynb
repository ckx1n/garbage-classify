{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "917ecdc7",
   "metadata": {},
   "source": [
    "## 整体数据探测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e31d1aee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_path= .\\data\\train_data\n",
      "Directory path = .\\data\\train_data\n",
      "total examples = 29604\n",
      "file name example: ['img_1.jpg', 'img_1.txt', 'img_10.jpg', 'img_10.txt', 'img_100.jpg']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from os import walk\n",
    "\n",
    "base_path='.\\data'\n",
    "data_path=os.path.join(base_path,'train_data')\n",
    "\n",
    "\n",
    "# 数据路径\n",
    "print('data_path=',data_path)\n",
    "\n",
    "for (dirpath,dirnames,filenames) in walk(data_path):\n",
    "    print('Directory path =',dirpath)\n",
    "    print('total examples =',len(filenames))    \n",
    "    print('file name example:',filenames[:5])    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82afa0ca",
   "metadata": {},
   "source": [
    "分析 *.txt 读取内容，然后取出img.txt\n",
    "首先，需要匹配.txt文件 进行输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f393732",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "def get_image_info():\n",
    "    \n",
    "    data_path_txt = os.path.join(data_path, '*.txt') #匹配所有.txt文件\n",
    "    txt_file_list=glob(data_path_txt)\n",
    "    \n",
    "#     print(txt_file_list[:2])\n",
    "    \n",
    "    #存储txt文件的变量\n",
    "    img_path_list=[]\n",
    "    \n",
    "    img_name2label_dict={}\n",
    "    \n",
    "    img_label_dict={}\n",
    "    \n",
    "    #读取文件中的内容\n",
    "    for file_path in txt_file_list:\n",
    "        with open(file_path,'r') as f:\n",
    "            line=f.readline()\n",
    "         \n",
    "        #文件内容\n",
    "#         print(line)\n",
    "        line=line.strip() \n",
    "        img_name=line.split(',')[0]\n",
    "        img_label=line.split(',')[1]\n",
    "        img_label=int(img_label)\n",
    "        \n",
    "        img_name_path=os.path.join(base_path,'train_data\\{}'.format(img_name))\n",
    "#         print(img_name_path)\n",
    "        #存储图片路径和标签\n",
    "        img_path_list.append({'img_name_path':img_name_path,'img_label':img_label})\n",
    "        \n",
    "        #图片名称-标签\n",
    "        img_name2label_dict[img_name]=img_label\n",
    "        \n",
    "        #统计每个标签出现的次数<img_label,img_count>\n",
    "        img_label_count=img_label_dict.get(img_label,0)\n",
    "        if img_label_count:\n",
    "            img_label_dict[img_label]=img_label_count+1\n",
    "        else:\n",
    "            img_label_dict[img_label]=1\n",
    "        \n",
    "        \n",
    "    return img_path_list,img_label_dict,img_name2label_dict\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70d0b556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img_path_list= [{'img_name_path': '.\\\\data\\\\train_data\\\\img_1.jpg', 'img_label': 0}, {'img_name_path': '.\\\\data\\\\train_data\\\\img_10.jpg', 'img_label': 0}, {'img_name_path': '.\\\\data\\\\train_data\\\\img_100.jpg', 'img_label': 0}]\n",
      "img_label_dict= {0: 242, 2: 279, 21: 657, 22: 375, 23: 309, 24: 318, 3: 85, 25: 550, 26: 351, 4: 387, 27: 536, 28: 382, 29: 416, 30: 321, 31: 446, 32: 280, 33: 322, 34: 395, 35: 351, 36: 265, 5: 289, 37: 322, 38: 391, 39: 437, 6: 395, 7: 362, 8: 380, 1: 370, 9: 389, 10: 387, 11: 736, 12: 331, 13: 409, 14: 357, 15: 419, 16: 352, 17: 309, 18: 362, 19: 312, 20: 226}\n",
      "img_label_dict len= 40\n"
     ]
    }
   ],
   "source": [
    "img_path_list,img_label_dict,img_name2label_dict=get_image_info()\n",
    "print('img_path_list=',img_path_list[:3])\n",
    "print('img_label_dict=',img_label_dict)\n",
    "print('img_label_dict len=',len(img_label_dict))\n",
    "# print('img_name2label_dict=',img_name2label_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ac98c9",
   "metadata": {},
   "source": [
    "## 切分数据集-训练集和验证集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c7f4b3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'img_name_path': '.\\\\data\\\\train_data\\\\img_1.jpg', 'img_label': 0},\n",
       " {'img_name_path': '.\\\\data\\\\train_data\\\\img_10.jpg', 'img_label': 0}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#原始数据格式\n",
    "\n",
    "img_path_list[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b14f9b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14802"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#原始数据大小\n",
    "len(img_path_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32912861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img_count= 14802\n",
      "train_size= 11841\n",
      "train_img_list size= 11841\n",
      "val_img_list size= 2961\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random.shuffle(img_path_list)#清洗原始数据\n",
    "\n",
    "#数据分布 0.8 0.2\n",
    "img_count=len(img_path_list)\n",
    "train_size=int(img_count*0.8)\n",
    "\n",
    "print('img_count=',img_count)\n",
    "print('train_size=',train_size)\n",
    "\n",
    "train_img_list=img_path_list[:train_size]\n",
    "val_img_list=img_path_list[train_size:]\n",
    "\n",
    "print('train_img_list size=',len(train_img_list))\n",
    "print('val_img_list size=',len(val_img_list))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11e126f",
   "metadata": {},
   "source": [
    "数据切分后 生成训练和验证数据了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673eaa83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "# 训练数据的生成\n",
    "with open(os.path.join(base_path,'garbage-classify-data/train.txt'),'w') as f:\n",
    "    for img_dict in train_img_list:\n",
    "        \n",
    "        #文本格式数据\n",
    "        img_name_path=img_dict['img_name_path']\n",
    "        img_label=img_dict['img_label']\n",
    "        \n",
    "        f.write(\"{}\\t{}\\n\".format(img_name_path,img_label))\n",
    "        \n",
    "        #图片-标签目录\n",
    "        garbage_classify_dir=os.path.join(base_path,'garbage-classify-data/train/{}'.format(img_label))\n",
    "        ##标签目录创建\n",
    "        if not os.path.exists(garbage_classify_dir):\n",
    "            os.makedirs(garbage_classify_dir)\n",
    "        \n",
    "        ##图片数据进行拷贝\n",
    "        shutil.copy(img_name_path,garbage_classify_dir)\n",
    "        \n",
    "\n",
    "#验证数据的生成\n",
    "with open(os.path.join(base_path,'garbage-classify-data/val.txt'),'w') as f:\n",
    "    for img_dict in val_img_list:\n",
    "        \n",
    "        #文本格式数据\n",
    "        img_name_path=img_dict['img_name_path']\n",
    "        img_label=img_dict['img_label']\n",
    "        \n",
    "        f.write(\"{}\\t{}\\n\".format(img_name_path,img_label))\n",
    "        \n",
    "        #图片-标签目录\n",
    "        garbage_classify_dir=os.path.join(base_path,'garbage-classify-data/val/{}'.format(img_label))\n",
    "        ##标签目录创建\n",
    "        if not os.path.exists(garbage_classify_dir):\n",
    "            os.makedirs(garbage_classify_dir)\n",
    "        \n",
    "        ##图片数据进行拷贝\n",
    "        shutil.copy(img_name_path,garbage_classify_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e7a218",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891eacc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1105d2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch_cpu] *",
   "language": "python",
   "name": "conda-env-pytorch_cpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
